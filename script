import os
import glob
import whisper
import torch

# ğŸ“ CrÃ©ation du dossier de sortie
os.makedirs("transcriptions", exist_ok=True)

# ğŸ” Recherche des fichiers audio
audio_files = glob.glob("*.mp3") + glob.glob("*.mp4")
if not audio_files:
    print("âŒ Aucun fichier audio trouvÃ©.")
    exit()

# ğŸš€ Chargement du modÃ¨le Whisper avec dÃ©tection auto GPU/CPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"âš™ï¸ Chargement du modÃ¨le Whisper sur : {device.upper()}")
model = whisper.load_model("small", device=device)

# ğŸ” Traitement de chaque fichier audio
for audio_file in audio_files:
    print(f"\nğŸµ Fichier dÃ©tectÃ© : {audio_file}")
    print("â³ Transcription en cours...")

    try:
        result = model.transcribe(audio_file)
        transcription = result["text"]
    except Exception as e:
        print(f"âŒ Erreur lors de la transcription : {e}")
        continue

    # ğŸ’¾ Sauvegarde de la transcription
    base_name = os.path.splitext(audio_file)[0]
    transcript_path = os.path.join("transcriptions", f"{base_name}_transcription.txt")
    with open(transcript_path, "w", encoding="utf-8") as f:
        f.write(transcription)
    print(f"âœ… Transcription enregistrÃ©e : {transcript_path}")

