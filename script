import os
import glob
import whisper
import torch

# 📁 Création du dossier de sortie
os.makedirs("transcriptions", exist_ok=True)

# 🔍 Recherche des fichiers audio
audio_files = glob.glob("*.mp3") + glob.glob("*.mp4")
if not audio_files:
    print("❌ Aucun fichier audio trouvé.")
    exit()

# 🚀 Chargement du modèle Whisper avec détection auto GPU/CPU
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"⚙️ Chargement du modèle Whisper sur : {device.upper()}")
model = whisper.load_model("small", device=device)

# 🔁 Traitement de chaque fichier audio
for audio_file in audio_files:
    print(f"\n🎵 Fichier détecté : {audio_file}")
    print("⏳ Transcription en cours...")

    try:
        result = model.transcribe(audio_file)
        transcription = result["text"]
    except Exception as e:
        print(f"❌ Erreur lors de la transcription : {e}")
        continue

    # 💾 Sauvegarde de la transcription
    base_name = os.path.splitext(audio_file)[0]
    transcript_path = os.path.join("transcriptions", f"{base_name}_transcription.txt")
    with open(transcript_path, "w", encoding="utf-8") as f:
        f.write(transcription)
    print(f"✅ Transcription enregistrée : {transcript_path}")

